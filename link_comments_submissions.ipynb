{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "46981298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from pyspark.sql import SparkSession, types\n",
    "from pyspark.sql.types import TimestampType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "2c46c0c8-fd76-416b-9b6b-1d8e826c46df",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('reddit-submissions-getter').getOrCreate()\n",
    "spark.sparkContext.setLogLevel('WARN')\n",
    "\n",
    "assert sys.version_info >= (3, 8) # make sure we have Python 3.8+\n",
    "assert spark.version >= '3.2' # make sure we have Spark 3.2+\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8ec348dd-1795-49de-99f9-9ad603dc63b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for stopping execution of the notebook\n",
    "class StopExecution(Exception):\n",
    "    def _render_traceback_(self):\n",
    "        return [\"ERROR: submissions already linked to comments\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "af91d331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_comment_sentiment_counts(comments_df, submissions_df):\n",
    "# given the comments and submissions dataframes, this function will split up the comments\n",
    "# by their link_id (the submission id) and count the number of positive, neutral and negative comments \n",
    "\n",
    "\n",
    "#sum the number of positive/netural/negative commetns for each unique link_id \n",
    "\n",
    "    comment_counts_df = comments_df.groupby(\"link_id\").agg(\n",
    "        positive_count=('sentiment_rounded', lambda x: (x == 1).sum()),\n",
    "        negative_count=('sentiment_rounded', lambda x: (x == -1).sum()),\n",
    "        neutral_count=('sentiment_rounded', lambda x: (x == 0).sum())\n",
    "    ).reset_index()\n",
    "    \n",
    "#remove  the \"t3_\" from link_id in the comments_df\n",
    "    comments_df['link_id'] = comments_df['link_id'].str.replace('t3_', '', regex=False)\n",
    "    \n",
    "#rename \"link_id\" to \"id\" in comment_counts_df so we can merge the dataframes on \"id\"\n",
    "\n",
    "    comment_counts_df.rename(columns={\"link_id\": \"id\"}, inplace=True)\n",
    "    \n",
    "#merge the dataframes on \"id\"\n",
    "    result_df = submissions_df.merge(comment_counts_df, on=\"id\", how=\"left\")\n",
    "    \n",
    "\n",
    "    result_df.fillna({'positive_count': 0, 'negative_count': 0, 'neutral_count': 0}, inplace=True)\n",
    "    \n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "9a615f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pivots the sentiment counts into seperate columns for each sentiment fill missing values with 0 \n",
    "def aggregate_sentiment_counts(comments_df):\n",
    "    sentiment_counts = comments_df.groupby(['link_id', 'sentiment_rounded']).size().unstack(fill_value=0)\n",
    "    sentiment_counts.columns = ['negative_count', 'neutral_count', 'positive_count'] \n",
    "    sentiment_counts.reset_index(inplace = True)\n",
    "    return sentiment_counts \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "dfde883e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjust these boundaries as needed \n",
    "\n",
    "def round_sentiment(score):\n",
    "    if score > 0.25:\n",
    "        return 1 \n",
    "    elif score < -0.25:\n",
    "        return -1 \n",
    "    else:\n",
    "        return 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c413e7a8-c305-4c88-b2ad-ebbe84790099",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to read multiple csv files in a directorty and load them into one single dataframe\n",
    "def load_csv_files(directory):\n",
    "    data_frames = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            try:\n",
    "                df = pd.read_csv(file_path, on_bad_lines='skip')  #avoid errors while reading \n",
    "                data_frames.append(df)\n",
    "            except pd.errors.ParserError as e:\n",
    "                print(f\"Error reading {file_path}: {e}\")\n",
    "    return pd.concat(data_frames, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "2a429d84-1140-45cc-b1aa-21a54f247bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions_df = load_csv_files('comments_cleaned/subs')\n",
    "comments_df = load_csv_files('comments_cleaned/comms')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ca25ea30-02a6-4b11-9d13-8e29d51a891f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'positive_count' in submissions_df.columns:\n",
    "    raise StopExecution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ecf4ec26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#round the sentiments to -1, 0 or 1 \n",
    "\n",
    "comments_df['sentiment_score'] = pd.to_numeric(comments_df['sentiment_score'], errors='coerce')\n",
    "submissions_df['sentiment_score'] = pd.to_numeric(submissions_df['sentiment_score'], errors='coerce')\n",
    "\n",
    "\n",
    "comments_df['sentiment_rounded'] = comments_df['sentiment_score'].apply(round_sentiment)\n",
    "submissions_df['sentiment_rounded'] = submissions_df['sentiment_score'].apply(round_sentiment)\n",
    "#add the comment sentiment counts to the submissions dataframe \n",
    "\n",
    "submissions_df = add_comment_sentiment_counts(comments_df, submissions_df)\n",
    "\n",
    "#group comments by link_id and count the number of each sentiment\n",
    "submissions = aggregate_sentiment_counts(comments_df)\n",
    "\n",
    "#match the column names for merging with submissions_df\n",
    "submissions.rename(columns={'link_id': 'id'}, inplace=True)\n",
    "\n",
    "#join with submissions_df\n",
    "submissions = submissions_df.merge(submissions, on = \"id\", how = \"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ac6964ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unnecessary columns added by the merge \n",
    "submissions = submissions.drop(columns=['positive_count_x', 'neutral_count_x', 'negative_count_x'])\n",
    "submissions = submissions.rename(columns={\n",
    "    'positive_count_y': 'positive_comment_count',\n",
    "    'neutral_count_y': 'neutral_comment_count',\n",
    "    'negative_count_y': 'negative_comment_count'\n",
    "}).fillna(0)\n",
    "submissions[['positive_comment_count', 'neutral_comment_count', 'negative_comment_count']]= submissions[['positive_comment_count', 'neutral_comment_count', 'negative_comment_count']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "63acdfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions_df['positive_count']=submissions['positive_comment_count']\n",
    "submissions_df['negative_count']=submissions['negative_comment_count']\n",
    "\n",
    "# remove sentiment_rounded from submissions_df\n",
    "submissions_df = submissions_df.drop(columns=['sentiment_rounded'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "eaebd31c-c6ac-4bf1-b749-05d50df91f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id    subreddit                                              title  \\\n",
      "0    1ea46c5  aznidentity        Recognize the Tactics of White Nationalists   \n",
      "1    1e9zbx9  aznidentity  Hung Cao Speaks at The 2024 Republican Nationa...   \n",
      "2    1e9eam1  aznidentity      Chinese language program for overseas Chinese   \n",
      "3    1e95w39  aznidentity  The 2024 USA International Mathematical Olympi...   \n",
      "4    1e95hy8  aznidentity  Re-Post of our Rules Regarding Trolling and Tr...   \n",
      "..       ...          ...                                                ...   \n",
      "237  1efztr6  programming    My mental model of setf was wrong [common lisp]   \n",
      "238  1efztds  programming         Data.Maybe, and thoughts on library design   \n",
      "239  1efzsyo  programming         Deno: What we got wrong about HTTP imports   \n",
      "240  1efzs27  programming                The evolution of Ruby's Range class   \n",
      "241  1efzrbv  programming         DARPA: Translating All C to Rust (Tractor)   \n",
      "\n",
      "    time_created  num_comments  sentiment_score  pop_score  controversial  \\\n",
      "0       03:10:08            16          -0.3216   0.809941          False   \n",
      "1       21:52:16            13           0.0000   0.000000           True   \n",
      "2       06:28:32             1          -0.3612   0.800000          False   \n",
      "3       21:52:16            27           0.9192   0.902275          False   \n",
      "4       21:28:48             0           0.0000   0.732697           True   \n",
      "..           ...           ...              ...        ...            ...   \n",
      "237     10:48:48             1          -0.4767   0.485670           True   \n",
      "238     10:48:48             0           0.0000   0.385643           True   \n",
      "239     10:48:48            23          -0.4767   0.849767          False   \n",
      "240     10:46:40             0           0.0000   0.500000           True   \n",
      "241     10:46:40             0           0.0000   0.563513           True   \n",
      "\n",
      "     positive_count  negative_count  neutral_count  \n",
      "0               5.0             1.0            0.0  \n",
      "1               2.0             1.0            0.0  \n",
      "2               0.0             0.0            0.0  \n",
      "3               4.0             0.0            0.0  \n",
      "4               0.0             0.0            0.0  \n",
      "..              ...             ...            ...  \n",
      "237             1.0             0.0            0.0  \n",
      "238             0.0             0.0            0.0  \n",
      "239             8.0             0.0            0.0  \n",
      "240             0.0             0.0            0.0  \n",
      "241             0.0             0.0            0.0  \n",
      "\n",
      "[242 rows x 11 columns]\n",
      "      link_id                                               body score  \\\n",
      "0     1ea49pc  Again, this reminds me of the White double sta...    34   \n",
      "1     1ecdu5y  I've often wondered about a specific trait amo...     5   \n",
      "2     1ectmty  You've summed it up nicely. I was born in the ...    10   \n",
      "3     1ea47zc  part of me wants to see how fucked up the U.S....    33   \n",
      "4     1ea47zc                               Still voting for him    -4   \n",
      "...       ...                                                ...   ...   \n",
      "2475  1eg2nuv  Now take the [highest paid CEO](https://aflcio...     1   \n",
      "2476  1eg0i39                       Don't just consider. Do it.      3   \n",
      "2477  1eg6dc9  It’s better to focus on lowering the cost of l...     1   \n",
      "2478  1eg2nuv  100 hours a week and still barely crossing $60...     1   \n",
      "2479  1eg2nuv  Pathetic try this. $4,145usd/week\\n\\nhttps://p...   -21   \n",
      "\n",
      "     time_created  sentiment_score  sentiment_rounded  \n",
      "0        09:32:00          -0.8360                 -1  \n",
      "1        14:07:12          -0.4404                 -1  \n",
      "2        01:53:20           0.9289                  1  \n",
      "3        05:45:52          -0.6597                 -1  \n",
      "4        22:17:52           0.0000                  0  \n",
      "...           ...              ...                ...  \n",
      "2475     15:32:32          -0.4767                 -1  \n",
      "2476     13:24:32           0.0000                  0  \n",
      "2477     15:45:20           0.5423                  1  \n",
      "2478     17:19:12           0.0000                  0  \n",
      "2479     13:39:28          -0.5719                 -1  \n",
      "\n",
      "[2480 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(submissions_df)\n",
    "print(comments_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "1e6dddde-e380-4e9a-86fb-1c1321698187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv \n",
    "# submissions_df.to_csv('submissions_cleaned_linked.csv', index=False)\n",
    "# comments_df.to_csv('comments_cleaned_linked.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "98b464fa-dbbe-4831-a53c-ab1dce56559f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# save to csv\n",
    "\n",
    "spark_subs = spark.createDataFrame(submissions_df)\n",
    "spark_subs.write.format(\"csv\").save(\"comments_cleaned/subs\", mode=\"overwrite\", header=True)\n",
    "\n",
    "# comments do not need saving bc the only new column is 'rounded_sentiment', which is not very useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22797b91-bba0-4a9a-acf4-6346bb22e6e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
